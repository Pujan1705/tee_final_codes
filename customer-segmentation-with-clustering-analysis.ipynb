{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Customer Segmentation","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import silhouette_score\nfrom scipy.cluster.hierarchy import dendrogram","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:11.569163Z","iopub.execute_input":"2023-04-22T16:30:11.570733Z","iopub.status.idle":"2023-04-22T16:30:11.578923Z","shell.execute_reply.started":"2023-04-22T16:30:11.57065Z","shell.execute_reply":"2023-04-22T16:30:11.577261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Introduction to Clustering\n\nClustering is the task of dividing the unlabeled data or data points into different clusters such that similar data points fall  \\\nin the same cluster than those which differ from the others. In simple words, the aim of the clustering process is to segregate groups with similar traits and assign them into clusters.\n\n<img src=\"https://i.stack.imgur.com/cIDB3.png\">","metadata":{}},{"cell_type":"markdown","source":"## Importing the Dataset","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('../input/customer-clustering/segmentation data.csv')","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:11.581206Z","iopub.execute_input":"2023-04-22T16:30:11.581574Z","iopub.status.idle":"2023-04-22T16:30:11.594352Z","shell.execute_reply.started":"2023-04-22T16:30:11.581518Z","shell.execute_reply":"2023-04-22T16:30:11.59334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:11.596405Z","iopub.execute_input":"2023-04-22T16:30:11.59671Z","iopub.status.idle":"2023-04-22T16:30:11.603648Z","shell.execute_reply.started":"2023-04-22T16:30:11.59666Z","shell.execute_reply":"2023-04-22T16:30:11.602462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop(['ID'], inplace=True, axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:11.604539Z","iopub.execute_input":"2023-04-22T16:30:11.604757Z","iopub.status.idle":"2023-04-22T16:30:11.612658Z","shell.execute_reply.started":"2023-04-22T16:30:11.60473Z","shell.execute_reply":"2023-04-22T16:30:11.612045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:11.613907Z","iopub.execute_input":"2023-04-22T16:30:11.614639Z","iopub.status.idle":"2023-04-22T16:30:11.629839Z","shell.execute_reply.started":"2023-04-22T16:30:11.614604Z","shell.execute_reply":"2023-04-22T16:30:11.628908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:11.631475Z","iopub.execute_input":"2023-04-22T16:30:11.631724Z","iopub.status.idle":"2023-04-22T16:30:11.668449Z","shell.execute_reply.started":"2023-04-22T16:30:11.631693Z","shell.execute_reply":"2023-04-22T16:30:11.667491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:11.670012Z","iopub.execute_input":"2023-04-22T16:30:11.670456Z","iopub.status.idle":"2023-04-22T16:30:11.682061Z","shell.execute_reply.started":"2023-04-22T16:30:11.670404Z","shell.execute_reply":"2023-04-22T16:30:11.680954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(21,15))\n\nplt.subplot2grid((2,2), (0,0))\nbox1 = sns.boxplot(y=data.Age)\nplt.title(\"Age\")\n\nplt.subplot2grid((2,2), (0,1))\nbox2 = sns.boxplot(y=data.Income)\nplt.title(\"Income\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:11.684598Z","iopub.execute_input":"2023-04-22T16:30:11.684953Z","iopub.status.idle":"2023-04-22T16:30:11.978071Z","shell.execute_reply.started":"2023-04-22T16:30:11.684907Z","shell.execute_reply":"2023-04-22T16:30:11.977011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.Age.describe()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:11.979539Z","iopub.execute_input":"2023-04-22T16:30:11.979852Z","iopub.status.idle":"2023-04-22T16:30:11.991184Z","shell.execute_reply.started":"2023-04-22T16:30:11.979809Z","shell.execute_reply":"2023-04-22T16:30:11.990109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.Income.describe()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:11.992487Z","iopub.execute_input":"2023-04-22T16:30:11.993271Z","iopub.status.idle":"2023-04-22T16:30:12.004429Z","shell.execute_reply.started":"2023-04-22T16:30:11.993226Z","shell.execute_reply":"2023-04-22T16:30:12.003699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inferences\n- Mean age is approximately 36 years. Max is 76 meanwhile Min is 18.\n- Mean income is 121k. Max is 310k meanwhile Min is 36k.","metadata":{}},{"cell_type":"markdown","source":"### Proportion of data values in each feature","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(21,15))\n\nplt.subplot2grid((3,3), (0,0))\nsns.histplot(data.Sex.astype(str), stat='proportion')\n\nplt.subplot2grid((3,3), (0,1))\nsns.histplot(data['Marital status'].astype(str), stat='proportion')\n\nplt.subplot2grid((3,3), (0,2))\nsns.histplot(data.Education.astype(str).sort_values(), stat='proportion')\n\nplt.subplot2grid((3,3), (1,0))\nsns.histplot(data.Occupation.astype(str).sort_values(), stat='proportion')\n\nplt.subplot2grid((3,3), (1,1))\nsns.histplot(data['Settlement size'].astype(str).sort_values(), stat='proportion')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:12.006703Z","iopub.execute_input":"2023-04-22T16:30:12.006956Z","iopub.status.idle":"2023-04-22T16:30:12.684852Z","shell.execute_reply.started":"2023-04-22T16:30:12.006923Z","shell.execute_reply":"2023-04-22T16:30:12.684086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Standardizing the Data","metadata":{}},{"cell_type":"code","source":"ss = StandardScaler()\ndata = pd.DataFrame(ss.fit_transform(data))","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:12.686087Z","iopub.execute_input":"2023-04-22T16:30:12.686474Z","iopub.status.idle":"2023-04-22T16:30:12.695397Z","shell.execute_reply.started":"2023-04-22T16:30:12.68644Z","shell.execute_reply":"2023-04-22T16:30:12.694405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# K Means Model\n\nK-means clustering is a popular unsupervised machine learning algorithm used to group data points with similar characteristics into K number of clusters. It works by first randomly assigning K number of centroids to the data points, and then iteratively adjusting the centroids to minimize the sum of squared distances between the data points and their assigned centroid. This process continues until convergence or until a maximum number of iterations is reached.\n\n<img src=\"https://av-eks-blogoptimized.s3.amazonaws.com/40672tb2.png\">","metadata":{}},{"cell_type":"markdown","source":"## Determining number of clusters : Elbow Method\n\nThe elbow method is a technique used to determine the optimal number of clusters in a dataset for k-means clustering. The method works by plotting the Within Cluster Sum of Squares (WCSS) between each data point and its assigned centroid for different values of K.\n\nAs K increases, the WCSS tends to decrease, since with more clusters, each data point is likely to be closer to its assigned centroid. However, beyond a certain point, the improvement in SSE becomes less significant, and the plot of WCSS versus K starts to form an elbow shape. For this, we will train multiple K means model with clusters ranging from 1-10.","metadata":{}},{"cell_type":"code","source":"wcss = {'wcss_score':[], 'no_of_clusters':[]}\nfor i in range(1,11):\n    kmeans = KMeans(i, random_state=0)\n    kmeans.fit(data)\n    wcss['wcss_score'].append(kmeans.inertia_)\n    wcss['no_of_clusters'].append(i)\nwcss_df = pd.DataFrame(wcss)","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:12.696986Z","iopub.execute_input":"2023-04-22T16:30:12.697445Z","iopub.status.idle":"2023-04-22T16:30:26.684381Z","shell.execute_reply.started":"2023-04-22T16:30:12.697385Z","shell.execute_reply":"2023-04-22T16:30:26.683618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wcss_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:26.688482Z","iopub.execute_input":"2023-04-22T16:30:26.691116Z","iopub.status.idle":"2023-04-22T16:30:26.706913Z","shell.execute_reply.started":"2023-04-22T16:30:26.691057Z","shell.execute_reply":"2023-04-22T16:30:26.706019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14,10))\nplt.plot(wcss_df.no_of_clusters, wcss_df.wcss_score, marker='o')\nplt.title(\"Elbow Method to determine number of clusters(K)\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:26.708443Z","iopub.execute_input":"2023-04-22T16:30:26.708738Z","iopub.status.idle":"2023-04-22T16:30:26.945212Z","shell.execute_reply.started":"2023-04-22T16:30:26.708696Z","shell.execute_reply":"2023-04-22T16:30:26.944168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference\nAt 4 clusters, we can see that the decrease in WCSS starts declining. Therefore, the number of clusters within this dataset is **4**\n* K = 4","metadata":{}},{"cell_type":"code","source":"kmeans_final = KMeans(n_clusters=4, random_state=0, init='k-means++')\nclasslabels = kmeans_final.fit_predict(data)","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:26.946812Z","iopub.execute_input":"2023-04-22T16:30:26.947143Z","iopub.status.idle":"2023-04-22T16:30:28.275802Z","shell.execute_reply.started":"2023-04-22T16:30:26.947106Z","shell.execute_reply":"2023-04-22T16:30:28.275033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['classlabels'] = classlabels\ndata.classlabels = data.classlabels.astype(str)\ndata = data.sort_values('classlabels')","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:28.280842Z","iopub.execute_input":"2023-04-22T16:30:28.283158Z","iopub.status.idle":"2023-04-22T16:30:28.295774Z","shell.execute_reply.started":"2023-04-22T16:30:28.283101Z","shell.execute_reply":"2023-04-22T16:30:28.294981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14,10))\nsns.histplot(data.classlabels)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:28.297149Z","iopub.execute_input":"2023-04-22T16:30:28.297651Z","iopub.status.idle":"2023-04-22T16:30:28.554931Z","shell.execute_reply.started":"2023-04-22T16:30:28.297612Z","shell.execute_reply":"2023-04-22T16:30:28.554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating our Model : Silhouette Score\n\nThe silhouette score is a metric used to evaluate the quality of clustering in a dataset. \\\nIt measures how similar a data point is to its own cluster compared to other clusters.\n\nThe silhouette score ranges from -1 to 1, with a higher score indicating better clustering performance. \\\nA score of 1 indicates that a data point is very similar to its own cluster and very dissimilar to other clusters, while a score of -1 indicates the opposite.\n\nTo calculate the silhouette score for a cluster, the average distance between a data point and all other points in the same cluster is first computed. \\\nThe average distance between the data point and all points in the nearest neighboring cluster is then calculated. The silhouette score for the data point is then given by the difference between these two values, divided by the maximum of the two.","metadata":{}},{"cell_type":"code","source":"score = silhouette_score(data, kmeans_final.labels_, random_state=0)\nprint(f\"Silhouette score: {score:0.3f} ~ 0\")","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:28.557532Z","iopub.execute_input":"2023-04-22T16:30:28.557765Z","iopub.status.idle":"2023-04-22T16:30:28.694318Z","shell.execute_reply.started":"2023-04-22T16:30:28.557736Z","shell.execute_reply":"2023-04-22T16:30:28.691079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Silhouette score of 0 means our model did not work very well. The worse could be -1, but the best can go upto 1.","metadata":{}},{"cell_type":"markdown","source":"# Hierarchical clustering - Agglomerative\n\nHierarchical clustering groups similar objects into a dendrogram. It merges similar clusters iteratively, starting with each data point as a separate cluster.  \\\nThis creates a tree-like structure that shows the relationships between clusters and their hierarchy.\n\nThe dendrogram from hierarchical clustering reveals the hierarchy of clusters at different levels, highlighting natural groupings in the data.  \\\nIt provides a visual representation of the relationships between clusters, helping to identify patterns and outliers, making it a useful tool for exploratory data analysis. For example:\n\nLet’s say we have the below points and we want to cluster them into groups:  \\\n<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2019/05/Screenshot-from-2019-05-15-13-10-32.png\" alt=\"\">\n\nWe can assign each of these points to a separate cluster:   \\\n<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2019/05/Screenshot-from-2019-05-15-13-11-28.png\" alt=\"\">\n\nNow, based on the similarity of these clusters, we can combine the most similar clusters together and repeat this process until only a single cluster is left:   \\\n<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2019/05/Screenshot-from-2019-05-15-13-12-35.png\" alt=\"\">\n\nWe are essentially building a hierarchy of clusters. That’s why this algorithm is called hierarchical clustering. This type of Hierarchical clustering is called **Agglomerative hierarchical clustering**. \\\nWe assign each point to an individual cluster in this technique. Then, at each iteration, we merge the closest pair of clusters and repeat this step until only a single cluster is left:   \\\n<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2019/05/Screenshot-from-2019-05-15-13-31-06.png\" alt=\"\">","metadata":{}},{"cell_type":"markdown","source":"To improve the clustering model, we move to hierarchical clustering","metadata":{}},{"cell_type":"code","source":"new_data = data.drop(['classlabels'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:28.695775Z","iopub.execute_input":"2023-04-22T16:30:28.698754Z","iopub.status.idle":"2023-04-22T16:30:28.705827Z","shell.execute_reply.started":"2023-04-22T16:30:28.69871Z","shell.execute_reply":"2023-04-22T16:30:28.704848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Distances and Linkages\n\nDistances and linkages are two key components of hierarchical clustering\n* **Distances**: Distances refer to the measure of dissimilarity or similarity between two data points in a dataset.\n* **Linkages**: Linkages refer to the method used to compute the distance between clusters during the clustering process.\n\nWith multiple computation options for both distance and linkage in clusters, we calculate the silhouette score for all permutations","metadata":{}},{"cell_type":"code","source":"## function to compute scores for all permutations\ndef s_score(distance, linkage):\n    agc = AgglomerativeClustering(n_clusters=4, affinity=distance, linkage=linkage)\n    agc.fit_predict(new_data)\n    score = silhouette_score(new_data, agc.labels_, random_state=0)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:28.70745Z","iopub.execute_input":"2023-04-22T16:30:28.708232Z","iopub.status.idle":"2023-04-22T16:30:28.715741Z","shell.execute_reply.started":"2023-04-22T16:30:28.708186Z","shell.execute_reply":"2023-04-22T16:30:28.714905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"distances = ['euclidean', 'l1', 'l2', 'manhattan', 'cosine']\nlinkages = ['ward', 'complete', 'average', 'single']","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:28.717153Z","iopub.execute_input":"2023-04-22T16:30:28.717485Z","iopub.status.idle":"2023-04-22T16:30:28.72762Z","shell.execute_reply.started":"2023-04-22T16:30:28.71744Z","shell.execute_reply":"2023-04-22T16:30:28.726557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scoring = {'dist':[], 'link':[], 'sScore':[]}\nfor i in distances:\n    for j in linkages:\n        try:\n            score = s_score(i, j)\n            scoring['dist'].append(i)\n            scoring['link'].append(j)\n            scoring['sScore'].append(score)\n        except:\n            scoring['dist'].append(i)\n            scoring['link'].append(j)\n            scoring['sScore'].append(np.nan)\nscoringDf = pd.DataFrame(scoring)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:28.728995Z","iopub.execute_input":"2023-04-22T16:30:28.72935Z","iopub.status.idle":"2023-04-22T16:30:31.632414Z","shell.execute_reply.started":"2023-04-22T16:30:28.729303Z","shell.execute_reply":"2023-04-22T16:30:31.631334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NOTE**: We put this process in try-except block since 'ward' only works with 'euclidean' distance. We can now find the best permutation.","metadata":{}},{"cell_type":"code","source":"scoringDf.dropna(axis=0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:31.633975Z","iopub.execute_input":"2023-04-22T16:30:31.63435Z","iopub.status.idle":"2023-04-22T16:30:31.64322Z","shell.execute_reply.started":"2023-04-22T16:30:31.63429Z","shell.execute_reply":"2023-04-22T16:30:31.641793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_result = scoringDf[scoringDf['sScore'] == max(scoringDf['sScore'])]\nfinal_result","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:30:31.645242Z","iopub.execute_input":"2023-04-22T16:30:31.645588Z","iopub.status.idle":"2023-04-22T16:30:31.663455Z","shell.execute_reply.started":"2023-04-22T16:30:31.64555Z","shell.execute_reply":"2023-04-22T16:30:31.66267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DBScan Clustering\n\n**DBSCAN** stands for **D**ensity-**B**ased **S**patial **C**lustering of **A**pplications with **N**oise.\n\nIt groups ‘densely grouped’ data points into a single cluster. It can identify clusters in large spatial datasets by looking at the local density of the data points.  \\\nThe most exciting feature of DBSCAN clustering is that it is robust to outliers. It also does not require the number of clusters to be told beforehand, unlike K-Means, where we have to specify the number of centroids.\n\nDBSCAN requires only two parameters: epsilon and minPoints. Epsilon is the radius of the circle to be created around each data point to check the density \\\nand minPoints is the minimum number of data points required inside that circle for that data point to be classified as a Core point\n\n<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/db26.png\" alt=\"\"> <br>\n\n#### This is what it looks like:  \n\n<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/db12.png\" alt=\"\"> <br>","metadata":{}},{"cell_type":"code","source":"dbs = DBSCAN(eps=2, min_samples=10)\ndbs.fit_predict(new_data)\nscore = silhouette_score(new_data, dbs.labels_, random_state=0)\nprint(f\"Silhouette score: {score:0.3f}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:33:54.401787Z","iopub.execute_input":"2023-04-22T16:33:54.402116Z","iopub.status.idle":"2023-04-22T16:33:54.625316Z","shell.execute_reply.started":"2023-04-22T16:33:54.402083Z","shell.execute_reply":"2023-04-22T16:33:54.62409Z"},"trusted":true},"execution_count":null,"outputs":[]}]}